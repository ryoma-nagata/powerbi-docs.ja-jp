---
title: Microsoft Power BI Premium 容量の最適化
description: Power BI Premium 容量の最適化戦略について説明します。
author: davidiseminger
ms.author: davidi
ms.reviewer: ''
ms.service: powerbi
ms.subservice: powerbi-admin
ms.topic: conceptual
ms.date: 04/09/2019
ms.custom: seodec18
LocalizationGroup: Premium
ms.openlocfilehash: 0486abd448158baafeaac3047bcb7b461470bac9
ms.sourcegitcommit: f77b24a8a588605f005c9bb1fdad864955885718
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 12/02/2019
ms.locfileid: "74699155"
---
# <a name="optimizing-premium-capacities"></a>Premium 容量を最適化する

Premium 容量のパフォーマンスに関する問題が発生した場合、最初に、ご自分のソリューションを最適化または調整して、許容可能な応答時間を復元するのが一般的な方法です。 理由は、妥当でない限り追加の Premium 容量の購入を避けるためです。

追加の Premium 容量が必要な場合は、この記事で説明されている 2 つのオプションがあります。

- 既存の Premium 容量をスケールアップする
- 新しい Premium 容量を追加する

最後は、テストの方法と Premium 容量のサイズ設定で、この記事を締めくくります。

## <a name="best-practices"></a>ベスト プラクティス

最適な使用率とパフォーマンスを得ようとする場合には、次のようないくつかのベスト プラクティスが推奨されます。

- 個人ワークスペースではなく、ワークスペースを使用する。
- ビジネス クリティカルおよびセルフサービス BI (SSBI) を異なる容量に分ける。

  ![ビジネス クリティカルおよびセルフサービス BI を異なる容量に分ける](media/service-premium-capacity-optimize/separate-capacities.png)

- Power BI Pro ユーザーとのみコンテンツを共有する場合、専用の容量にコンテンツを格納する必要はないかもしれません。
- 特定の更新時間を実現しようとしている場合、または特定の機能が必要な場合は、専用の容量を使用する。 たとえば、大規模なデータセットやページ分割されたレポートがある場合です。

### <a name="addressing-common-questions"></a>一般的な質問への対処

Power BI Premium のデプロイの最適化は、ワークロード要件、利用可能なリソース、およびそれらの効果的な使用についての理解が必要とされる複雑なテーマです。

この記事では、サポートによく寄せられる 7 つの質問に対処して、考えられる問題と理由のほか、それらを特定して解決する方法に関する情報を説明します。

### <a name="why-is-the-capacity-slow-and-what-can-i-do"></a>容量が遅いのはなぜですか。どうすればよいですか。

Premium 容量が遅くなるには多くの理由が考えられます。 この質問では、"遅い" が何を意味しているかを理解するためにさらに情報が必要です。 レポートの読み込みが遅いのでしょうか。 それとも、それらの読み込みが失敗するのでしょうか。 ユーザーがレポートを操作するときに、レポートのビジュアルの読み込みまたは更新が遅いのでしょうか。 予想または以前の実行時より、更新の完了に時間がかかっているのでしょうか。

理由を把握できたら、調査を開始することができます。 次の 6 つの質問に対する回答は、より具体的な問題に対処するのに役立ちます。

### <a name="what-content-is-using-up-my-capacity"></a>容量は何のコンテンツに使用されていますか。

**Power BI Premium 容量メトリック** アプリを使用して、容量単位でフィルター処理したり、ワークスペースのコンテンツのパフォーマンス メトリックを確認したりできます。 Premium 容量内に格納されたすべてのコンテンツについて、過去 7 日間のパフォーマンス メトリックとリソースの使用状況を 1 時間単位で確認できます。 監視は多くの場合、Premium 容量のパフォーマンスに関する一般的な問題のトラブルシューティング時に実行する最初の手順です。

監視する主要なメトリックは次のとおりです。

- 平均 CPU と使用率が高かった回数。
- 平均メモリと使用率が高かった回数、および特定のデータセット、データフロー、ページ分割されたレポートでのメモリ使用量。
- メモリに読み込まれたアクティブなデータセット。
- 平均および最大のクエリ時間。
- 平均クエリ待機時間。
- データセットとデータフローの平均更新時間。

Power BI Premium 容量メトリック アプリでは、アクティブなメモリは、過去 3 分間に使用中だったため削除できないレポートに与えられたメモリの総容量を示します。 更新の待機時間における急増は、大規模なデータセットやアクティブなデータセットと相関がある可能性があります。

**平均実行時間に基づいた上位 5 位**のグラフでは、容量リソースを消費している上位 5 位のデータセット、ページ分割されたレポート、データフローが強調表示されます。 上位 5 位のリストにあるコンテンツは、調査の候補であり、最適化できる可能性があります。

### <a name="why-are-reports-slow"></a>レポートが遅いのはなぜですか。

次の表では、考えられる問題と、それらを特定して処理する方法を示しています。

#### <a name="insufficient-capacity-resources"></a>容量リソースの不足

| 考えられる理由 | 特定する方法 | 解決する方法 |
| --- | --- | --- |
| アクティブなメモリの総量が多い (モデルは過去 3 分間に使用中だったため削除できません)。<br><br> クエリ待機時間における複数の急増。<br><br> 更新の待機時間における複数の急増。 | メモリのメトリック \[[1](#endnote-1)\] と削除数 \[[2](#endnote-2)\] を監視する。 | モデルのサイズを縮小する。または、DirectQuery モードに切り替える。 この記事の「[モデルの最適化](#optimizing-models)」セクションを参照してください。<br><br> 容量をスケールアップする。<br><br> コンテンツを別の容量に割り当てる。 |

#### <a name="inefficient-report-designs"></a>非効率的なレポート デザイン

| 考えられる理由 | 特定する方法 | 解決する方法 |
| --- | --- | --- |
| レポート ページに含まれるビジュアルが多すぎる (対話型のフィルター処理で、ビジュアルごとに少なくとも 1 つのクエリがトリガーされる可能性があります)。<br><br> ビジュアルで必要以上のデータが取得される。 | レポート デザインを確認する。<br><br> レポートのユーザーにインタビューして、レポートをどのように操作しているかを把握する。<br><br> データセット クエリのメトリック \[[3](#endnote-3)\] を監視する。 | レポートをデザインし直して、1 ページあたりのビジュアルを少なくする。 |

#### <a name="dataset-is-slow-especially-when-reports-have-previously-performed-well"></a>データセットが遅い (特に、レポートがこれまで正常に実行されていた場合)

| 考えられる理由 | 特定する方法 | 解決する方法 |
| --- | --- | --- |
| 増加し続ける大量のインポート データ。<br><br> 複雑または非効率的な計算ロジック (RLS ロールなど)。<br><br> モデルが完全には最適化されていない。<br><br> (DQ/LC) ゲートウェイの待ち時間。<br><br> DQ のソース クエリ応答時間が長い。 | モデルのデザインを確認する。<br><br> ゲートウェイのパフォーマンス カウンターを監視する。 | この記事の「[モデルの最適化](#optimizing-models)」セクションを参照してください。 |

#### <a name="high-concurrent-report-usage"></a>レポートの同時使用率が高い

| 考えられる理由 | 特定する方法 | 解決する方法 |
| --- | --- | --- |
| クエリ待機時間が長い。<br><br> CPU の飽和。<br><br> DQ/LC 接続の制限を超過した。 | CPU 使用率 \[[4](#endnote-4)\]、クエリ待機時間、DQ/LC 使用率 \[[5](#endnote-5)\] メトリックおよびクエリ時間を監視する。 変動がある場合は、コンカレンシーの問題を示している可能性があります。 | 容量をスケールアップする。または、コンテンツを別の容量に割り当てる。<br><br> レポートをデザインし直して、1 ページあたりのビジュアルを少なくする。 |

**注:**    
<a name="endnote-1"></a>\[1\] 平均メモリ使用量 (GB)、および最高メモリ消費量 (GB)。   
<a name="endnote-2"></a>\[2\] データセットの削除数。   
<a name="endnote-3"></a>\[3\] データセット クエリ、データセットの平均クエリ時間 (ミリ秒)、データセットの待機数、データセットの平均待機時間 (ミリ秒)。   
<a name="endnote-4"></a>\[4\] CPU の使用率が高かった回数と、使用率が最も高かった CPU 時間 (過去 7 日間)。   
<a name="endnote-5"></a>\[5\] DQ/LC の使用率が高かった回数と、使用率が最も高かった DQ/LC 時間 (過去 7 日間)。   

### <a name="why-are-reports-not-loading"></a>レポートが読み込まれないのはなぜですか。

レポートの読み込みが失敗する場合、それは、容量のメモリが足りておらず、過負荷状態であることの明らかな兆候です。 これが発生する可能性があるのは、読み込まれたすべてのモデルでクエリがアクティブに実行されているため削除ができず、すべての更新操作が一時停止または遅延している場合です。 Power BI サービスは、データセットの読み込みを 30 秒間試行します。ユーザーには失敗が速やかに通知され、すぐに再試行するよう提案されます。

現在、レポートの読み込みエラーについて監視するメトリックはありません。 システム メモリ (具体的には、最も高い使用率と使用率が最も高い時間) を監視することで、この問題が発生する可能性を特定することができます。 データセットの削除数が多いこと、およびデータセットの更新にかかる平均待機時間が長いことは、この問題の発生を示唆している可能性があります。

これは発生する頻度が非常に低い場合、優先度の高い問題と見なさなくてよいかもしれません。 レポートのユーザーには、サービスがビジー状態である旨と、しばらくしてから再試行する必要がある旨が伝えられます。 これがあまりにも頻繁に発生する場合は、Premium 容量をスケールアップするか、コンテンツを別の容量に割り当てるかして、この問題を解決することができます。

容量管理者 (および Power BI サービス管理者) は、**クエリの失敗**のメトリックを監視して、これが発生するタイミングを調べることができます。 システムのオーバーロードが発生した際はすべての操作をリセットして、容量を再起動することもできます。

### <a name="why-are-refreshes-not-starting-on-schedule"></a>更新がスケジュールどおりに開始されないのはなぜですか。

スケジュールされた更新の開始時刻は保証されません。 Power BI サービスでは常にバックグラウンド操作よりも対話型の操作が優先されることを思い出してください。 更新は、2 つの条件が満たされている場合に行われるバックグラウンド操作です。

- 十分なメモリがある
- Premium 容量でサポートされている同時更新の数を超過していない

条件が満たされていない場合、条件が整うまで、更新はキューに入れられます。

完全な更新には、現在のデータセット サイズの少なくとも 2 倍のメモリが必要であることを思い出してください。 十分なメモリが使用可能でない場合、モデルの削除によってメモリが解放されるまで、更新は開始できません。これは、1 つまたは複数のデータセットが非アクティブになり、それらを削除できるまで、遅延が生じることを意味します。

サポートされている最大同時更新の数は、バックエンド仮想コア数の 1.5 倍 (切り上げ) に設定されていることを思い出してください。

スケジュールされた更新は、次のスケジュールされた更新の開始期限までに開始できない場合に失敗します。 UI でオンデマンド更新を手動でトリガーすると、失敗するまでに最大で 3 回、実行が試行されます。

容量管理者 (および Power BI サービス管理者) は、**更新の平均待機時間 (分)** のメトリックを監視して、スケジュールされた時刻と操作の開始との間における平均ラグを調べることができます。

通常は管理上の優先事項ではありませんが、データの更新が時間どおり行われるように、十分なメモリを使用可能にしておいてください。 これには、既知の十分なリソースがある容量にデータセットを分離することが必要な場合があります。 競合を最小限に抑えるために、管理者はデータセットの所有者と連携して、スケジュールされたデータの更新時間を調整したり減らしたりすることもできます。 管理者は更新のキューを表示したり、データセットのスケジュールを取得したりできないことに注意してください。

### <a name="why-are-refreshes-slow"></a>更新が遅いのはなぜですか。

更新は遅い場合、または遅く感じられる場合 (前のよくある質問で解決されるため) があります。

実際に更新が遅い場合は、その原因としていくつかの理由が考えられます。

- CPU の不足 (更新で CPU に高い負荷がかかる可能性があります)。
- メモリの不足。結果として更新が一時停止します (この場合、再開する条件が整ったときに更新をやり直す必要があります)。
- 容量以外の理由。データソース システムの応答性、ネットワーク待ち時間、無効なアクセス許可、ゲートウェイのスループットなど。
- データ ボリューム。下記で説明するように、増分更新を構成する正当な理由です。

容量管理者 (および Power BI サービス管理者) は、経時的な比較のベンチマークを調べるために**平均更新時間 (分)** のメトリックを、また、スケジュールされた時刻と操作の開始との間における平均ラグを調べるために**更新の平均待機時間 (分)** のメトリックを監視できます。

増分更新では、特にモデル テーブルが大きい場合に、データの更新時間を大幅に短縮できます。 増分更新には 4 つのメリットがあります。

- **更新がより高速である** - 読み込みが必要なのはテーブルのサブセットだけであるため、CPU とメモリの使用量が抑えられます。また、複数のパーティションを更新する場合、並列処理がより高度になる可能性があります。
- **必要な場合にのみ更新が行われる** - 増分更新ポリシーは、データが変更された場合にのみ読み込みを行うよう構成できます。
- **更新の信頼性が高くなる** - 揮発性のデータソース システムへの接続を実行する時間が短くなり、切断の影響を受けにくくなります。
- **モデルがコンパクトに保たれる** - 増分更新ポリシーは、時間のスライディング ウィンドウを超えた履歴を自動的に削除するよう構成できます。

詳細については、「[Power BI Premium での増分更新](service-premium-incremental-refresh.md)」を参照してください。

### <a name="why-are-data-refreshes-not-completing"></a>データの更新が完了しないのはなぜですか。

データの更新が開始しても完了に失敗する場合は、その原因としていくつかの理由が考えられます。

- メモリの不足。Premium 容量に 1 つしかモデルがない場合でも、モデルのサイズが非常に大きいことがあります。
- 容量以外の理由。データソース システムの切断、無効なアクセス許可、ゲートウェイ エラーなど。

容量管理者 (および Power BI サービス管理者) は、**メモリ不足による更新の失敗**のメトリックを監視できます。

## <a name="optimizing-models"></a>モデルの最適化

最適なモデルのデザインは、効率的でスケーラブルなソリューションの実現に不可欠です。 しかし、完全な説明を提供することは、この記事の範囲外です。 代わりに、このセクションでは、モデルを最適化する際に考慮すべき主な領域について説明します。

### <a name="optimizing-power-bi-hosted-models"></a>Power BI でホストされるモデルの最適化

Premium 容量でホストされるモデルの最適化は、データソースおよびモデルのレイヤーで実現できます。

インポート モデルの最適化の可能性を検討します。

![インポート モデルの最適化の可能性](media/service-premium-capacity-optimize/import-model-optimizations.png)

データソース レイヤー:

- 可能な限りすばやく更新が行われるように、データの事前統合、適切なインデックスの適用、増分更新の期間に合うテーブル パーティションの定義、計算の具体化 (モデルの計算テーブルおよび計算列の代わり) またはビューへの計算ロジックの追加によって、リレーショナル データ ソースを最適化できます。
- 非リレーショナル データ ソースは、リレーショナル ストアと事前に統合できます。
- ゲートウェイに十分なリソースを確保します。できれば、専用のマシンを用意し、ネットワーク帯域幅の不足がないようにして、データ ソースとの距離を近くします。

モデル レイヤー:

- Power Query のクエリ デザインでは、複雑な変換、特にさまざまなデータ ソースをマージするものを最小限に抑えたり、削除したりできます (これは、抽出、変換、読み込みのステージにおいてデータ ウェアハウスによって実現されます)。 また、適切なデータソース プライバシー レベルを設定するようにします。これにより、クエリ全体の結合された結果を生成するために Power BI がすべての結果を読み込む必要がなくなります。
- モデルの構造は、読み込むデータを決定し、モデルのサイズに直接影響します。 これは、列を削除したり、行 (特に履歴データ) を削除したり、(詳細なデータを読み込む代わりに) 要約されたデータを読み込んだりすることで、不要なデータの読み込みを避けるように設計できます。 格納または圧縮があまり効率的でない、カーディナリティが高い列 (特にテキスト列) を削除して、大幅なサイズ削減を実現できます。
- 双方向のフィルター処理を可能にする魅力的な理由がない限り、モデルのクエリ パフォーマンスは一方向のリレーションシップを構成して向上させることができます。 双方向のフィルター処理ではなく、[CROSSFILTER](https://docs.microsoft.com/dax/crossfilter-function) 関数を使用することも検討してください。
- 集計テーブルでは、事前に要約されたデータを読み込むことで、迅速なクエリ応答を実現できます。ただし、それによってモデルのサイズが増加し、更新時間が長くなります。 一般に、集計テーブルは、非常に大規模なモデルまたは複合モデルのデザインのために予約される必要があります。
- 計算テーブルおよび計算列を使用すると、モデルのサイズが増加し、更新時間が長くなります。 一般に、データがデータソースで具体化または計算される場合に、ストレージ サイズを小さくし、更新時間を短縮できます。 これが不可能な場合は、Power Query のカスタム列を使用することで、ストレージ圧縮の改善を実現できます。
- メジャーと RLS ルールの DAX 式を調整することができます (不経済な式を避けるためのロジックの書き直しなど)
- 増分更新では、更新時間を大幅に短縮し、メモリと CPU を節約することができます。 さらに増分更新は、モデルのサイズをコンパクトに保つために履歴データを削除するよう構成することもできます。
- クエリ パターンが異なったり競合したりしている場合、1 つのモデルを 2 つのモデルにデザインし直すことができます。 たとえば、一方のレポートでは、すべての履歴にわたる高レベルの集計が表示され、24 時間の待ち時間が許容されます。 他方のレポートは今日のデータに関するものであり、個々のトランザクションへの詳細なアクセスが必要です。 すべてのレポートで満足のいく単一のモデルをデザインするのではなく、それぞれの要件に合わせて最適化された 2 つのモデルを作成します。

DirectQuery モデルの最適化の可能性を検討します。 このモデルでは、基になるデータソースに対してクエリ要求が発行されるため、データソースの最適化が、レスポンシブなモデル クエリの実現に不可欠です。

 ![DirectQuery モデルの最適化の可能性](media/service-premium-capacity-optimize/direct-query-model-optimizations.png)

データソース レイヤー:

- 可能な限りすばやくクエリが実行されるように、データの事前統合 (これはモデル レイヤーではできません)、適切なインデックスの適用、テーブル パーティションの定義、(インデックス付きビューによる) 要約されたデータの具体化、計算量の最小化によって、データソースを最適化できます。 パススルー クエリで実行する必要があるのが、インデックス付きのテーブルまたはビューの間でのフィルター処理と内部結合のみである場合に、最善のエクスペリエンスが得られます。
- ゲートウェイに十分なリソースを確保します。できれば、専用のマシンを用意し、ネットワーク帯域幅の不足がないようにして、データソースとの距離を近くします。

モデル レイヤー:

- Power Query のクエリ デザインでは、なるべく変換を適用しないようにする必要があります。そうでなければ、変換を最小限に留めるよう試みてください。
- 双方向のフィルター処理を可能にする魅力的な理由がない限り、モデルのクエリ パフォーマンスは一方向のリレーションシップを構成して向上させることができます。 さらに、(この場合には) 参照整合性が強制されることを想定するように、モデルのリレーションシップを構成する必要があります。その結果データソース クエリで、(外部結合ではなく) より効率的な内部結合が使用されるようになります。
- Power Query のクエリ カスタム列またはモデルの計算列を作成しないようにします。これらは、可能であればデータソースで具体化します。
- メジャーと RLS ルールの DAX 式を調整することができます (不経済な式を避けるためのロジックの書き直しなど)。

複合モデルの最適化の可能性を検討します。 複合モデルでは、インポートと DirectQuery のテーブルを組み合わせられることを思い出してください。

![複合モデルの最適化の可能性](media/service-premium-capacity-optimize/composite-model-optimizations.png)

- 一般に、インポートおよび DirectQuery モデルの最適化は、それらのストレージ モードが使用される複合モデル テーブルにも当てはまります。
- 通常、ディメンションタイプのテーブル (ビジネス エンティティを表す) をデュアル ストレージ モード、ファクトタイプのテーブル (多くの場合大規模なテーブルで、操作上のファクトを表す) を DirectQuery ストレージ モードとして構成することで、バランスの取れたデザインを実現するよう心がけます。 デュアル ストレージ モードでは、インポートと DirectQuery の両方のストレージ モードが使用されます。これにより、Power BI サービスで、パススルー用のネイティブ クエリを生成する際に使用する、より効率的なストレージ モードを決定できます。
- ゲートウェイに十分なリソースを確保します。できれば、専用のマシンを用意し、ネットワーク帯域幅の不足がないようにして、データ ソースとの距離を近くします
- インポート ストレージ モードとして構成された集計テーブルは、DirectQuery ストレージ モードのファクトタイプ テーブルを要約するために使用すると、クエリ パフォーマンスの大幅な向上を実現できます。 この場合、集計テーブルによってモデルのサイズが増加するほか、更新時間が増加します。これは多くの場合、クエリ速度の向上に対するトレードオフとして許容されます。

### <a name="optimizing-externally-hosted-models"></a>外部でホストされるモデルの最適化

「[Power BI でホストされるモデルの最適化](#optimizing-power-bi-hosted-models)」セクションで説明した多くの最適化の可能性は、Azure Analysis Services および SQL Server Analysis Services を使用して開発されたモデルにも当てはまります。 複合モデルや集計テーブルなど、現在サポートされていない特定の機能は、明らかな例外です。

外部でホストされるデータセットの場合、Power BI サービスに関連するデータベースのホストについても考慮する必要があります。 Azure Analysis Services の場合、これは、Power BI テナントと同じリージョン (ホーム リージョン) で Azure リソースを作成することを意味します。 SQL Server Analysis Services の場合、これは、IaaS では同じリージョン内で VM をホストすること、オンプレミスでは効率的なゲートウェイの設定を確実に行うことを意味します。

付け加えると、Azure Analysis Services データベースと SQL Server Analysis Services 表形式データベースでは、それらのモデルがメモリに完全に読み込まれる必要があるほか、クエリをサポートするためにはそれらが常にそこに保持される必要があることに注意するとよいかもしれません。 Power BI サービスと同様に、モデルが更新中にオンラインのままでなければならない場合は、更新に十分なメモリが必要になります。 Power BI サービスとは異なり、使用量に応じてモデルがメモリに自動的に出し入れされるという概念はありません。 そのため、Power BI Premium には、より効率的なアプローチが用意されており、メモリ使用量を抑えながらモデルのクエリを最大限に活用できます。

## <a name="capacity-planning"></a>キャパシティ プランニング

Premium 容量のサイズによって、使用可能なメモリおよびプロセッサ リソースと、容量に課される制限が決まります。 複数の Premium 容量を作成することはワークロードを互いに分離するのに役立つため、Premium 容量の数も考慮事項です。 ストレージは容量ノードあたり 100 TB であることに注意してください。これは、どのワークロードでも十分すぎるでしょう。

Premium 容量のサイズと数を決定するのは難しい場合があります。特に、最初の容量を作成する場合です。 容量のサイズ設定を行う際の最初の手順は、予想される日々の使用量を表す平均ワークロードを理解することです。 すべてのワークロードが等しいわけではないことを理解するのが重要です。 たとえば一方で、単一のビジュアルが含まれている単一のレポート ページに 100 人のユーザーが同時にアクセスできるようにすることは簡単です。 しかし他方で、それぞれのレポート ページに 100 個のビジュアルがある 100 個の異なるレポートに、100 人のユーザーが同時にアクセスできるようにする場合は、容量リソースに関する非常にさまざまな要件が発生します。

そのため、容量管理者は、実際の環境、コンテンツ、予想される使用状況に固有な多数の要因を考慮する必要があります。 最も重要な目標は、一貫したクエリ時間、許容可能な待機時間、削除率を実現しながら、容量の使用率を最大化することです。 考慮すべき要因には次のようなものがあります。

- **モデルのサイズとデータの特性** - クエリまたは更新を可能にするには、インポート モデルをメモリに完全に読み込む必要があります。 LC/DQ データセットでは、複雑なメジャーまたは RLS ルールを評価するために、かなりのプロセッサ時間と場合によっては大量のメモリが必要なことがあります。 メモリとプロセッサのサイズ、および LC/DQ クエリ スループットは、容量のサイズによって制限されます。
- **同時アクティブ モデル** - 異なるインポート モデルの同時クエリでは、それらがメモリ内に保持されている場合に、最高の応答性とパフォーマンスが実現されます。 大量のクエリが実行されるモデルをすべてホストするには、十分なメモリが必要です。追加のメモリによって、それらの更新が可能になります。
- **インポート モデルの更新** - 更新の種類 (完全または増分)、Power Query クエリの時間と複雑さ、および計算テーブルまたは計算列のロジックは、メモリと特にプロセッサの使用率に影響を及ぼす可能性があります。 同時更新は、容量のサイズ (バックエンド仮想コア数の 1.5 倍 (切り上げ)) によって制限されます。
- **同時クエリ** - 同時クエリが多数の場合、プロセッサまたは LC/DQ 接続が容量の制限を超えたときに、レポートが応答しなくなる可能性があります。 これは特に、多数のビジュアルが含まれているレポート ページの場合に当てはまります。
- **データフローとページ分割されたレポート** - 容量は、データフローとページ分割されたレポートをサポートするよう構成できます。それぞれ、構成可能な最大の割合の容量メモリが必要です。 メモリは、データフローには動的に割り当てられますが、ページ分割されたレポートには静的に割り当てられます。

これらの要因に加えて、容量管理者は複数の容量の作成を検討できます。 複数の容量では、ワークロードの分離が可能であり、優先度の高いワークロードのためにリソースが確保されるよう構成できます。 たとえば、セルフサービス BI (SSBI) ワークロードからビジネスクリティカルなワークロードを分離させるために、2 つの容量を作成できます。 ビジネスクリティカルな容量は、会社の大規模なモデルを分離してそれらにリソースを確保するために使用できます。作成アクセス権は IT 部門にのみ付与します。 SSBI 容量は、数を増す小規模なモデルをホストするために使用できます。アクセス権はビジネス アナリストに付与します。 SSBI 容量では、許容できるクエリまたは更新の待機が発生する場合があります。

容量管理者は、ワークスペース間でコンテンツを (または容量間でワークスペースを) 移動したり、容量をスケールアップ/ダウンしたりして、時間の経過と共に容量全体でワークスペースを調整できます。 一般に、より大きなモデルをホストするにはスケールアップし、コンカレンシーを向上させるにはスケールアウトします。

ライセンスを購入するとテナントに仮想コアが追加されることを思い出してください。 **P3** サブスクリプションの購入は、1 つまたは最大で 4 つの Premium 容量の作成に使用できます (1 x P3、2 x P2、または 4 x P1)。 さらに、P2 容量を P3 容量にアップサイズする前に、仮想コアを分割して 2 つの P1 容量を作成することも検討できます。

## <a name="testing-approaches"></a>テスト方法

容量のサイズが決定したら、制御された環境を作成してテストを実行できます。 実際的かつ経済的なのは、Azure (A SKU) 容量を作成する方法です。P1 容量は A4 容量と同じサイズであり、P2 および P3 容量はそれぞれ A5 および A6 容量と同じサイズであることに注意してください。 Azure 容量はすぐに作成することができ、時間単位で課金されます。 そのため、テストが完了したら、コストが発生しないようにそれらを簡単に削除できます。

テストのコンテンツは Azure 容量上に作成されたワークスペースに追加できます。そして、単一ユーザーはレポートを実行して、現実的で代表的なクエリのワークロードを生成できます。 インポート モデルがある場合、各モデルの更新も実行する必要があります。 また、すべてのメトリックを確認してリソース使用率を把握するために監視ツールを使用できます。

テストは反復可能であることが重要です。 テストは数回実行する必要があり、その結果は毎回ほぼ同じになる必要があります。 これらの結果の平均は、実際の運用条件下でのワークロードを推定および予測するために使用できます。

ロード テストを行いたい容量とレポートが既にある場合は、[PowerShell ロード生成ツール](https://aka.ms/PowerBILoadTestingTool)を使用して、ロード テストをすばやく生成します。 このツールでは、ご自分の容量で 1 時間に実行できる各レポートのインスタンス数を予測できます。 ツールを使用して、個別のレポートの表示またはいくつかの異なるレポートの並列表示に関する、自分の容量の能力を評価できます。 詳細については、次のビデオを参照してください: [Microsoft Power BI: Premium 容量](https://www.youtube.com/watch?time_continue=1860&v=C6vk6wk9dcw)。

より複雑なテストを生成するには、現実的なワークロードをシミュレートするロード テスト アプリケーションの開発を検討してください。 詳細については、ウェビナー「[Power BI のロード テスト アプリケーションと Visual Studio ロード テスト](https://powerbi.microsoft.com/blog/week-4-11-webinars-load-testing-power-bi-applications-with-visual-studio-load-test-and-getting-started-with-cds-for-apps-based-model-driven-apps/)」を参照してください。

## <a name="acknowledgements"></a>謝辞

この記事は、データ プラットフォーム MVP であり、[Bitwise Solutions](https://www.bitwisesolutions.com.au/) の独立 BI 専門家である Peter Myers によって執筆されました。

## <a name="next-steps"></a>次の手順

> [!div class="nextstepaction"]
> [Premium 容量のシナリオ](service-premium-capacity-scenarios.md)   
  
他にわからないことがある場合は、 [Power BI コミュニティで質問してみてください](https://community.powerbi.com/)。

||||||